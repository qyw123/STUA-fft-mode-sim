# VCore 向量处理核心

VCore是本SOC系统中的核心计算单元，专为高性能向量和矩阵运算设计。它集成了多个功能子模块，形成完整的计算加速架构。

## 架构组成

VCore由以下主要组件构成：

1. **AM (Activation Memory)**: 
   - 激活值存储器，用于存储神经网络中的激活值或中间计算结果
   - 支持高带宽并行访问，优化数据流水线
   - 为VPU和PEA提供数据缓存

2. **SM (Scratchpad Memory)**:
   - 高速暂存内存，用于临时计算数据的快速访问
   - 比AM更小但速度更快，用于频繁访问的数据
   - 支持低延迟、高带宽的数据交换

3. **DMA (Direct Memory Access)**:
   - 负责VCore与外部存储(DDR、GSM)之间的高效数据传输
   - 支持块传输模式，减少CPU干预
   - 实现复杂的数据重排和格式转换
   - 包含多通道并行传输能力

4. **VPU (Vector Processing Unit)**:
   - 向量处理单元，执行SIMD (单指令多数据)操作
   - 支持向量加法、乘法、激活函数等基本运算
   - 针对浮点和定点数据类型优化
   - 包含专用寄存器组和向量ALU

5. **SPU (Scalar Processing Unit)**:
   - 标量处理单元，处理控制流和非向量化计算
   - 执行条件判断、循环控制等操作
   - 管理计算任务的调度和同步

; 6. **PEA (Processing Element Array)**:
;    - 处理单元阵列，主要用于矩阵乘法等密集计算
;    - 采用脉动阵列架构，实现高度并行化
;    - 包含多个处理元素(PE)，形成二维计算网格

## 数据流

VCore内部数据流遵循以下典型模式：

1. DMA从外部存储(DDR或GSM)加载数据到AM或SM
2. 计算单元(VPU、SPU或PEA)从AM/SM读取输入数据
3. 计算单元执行指定运算
4. 结果写回AM/SM
5. 最终结果通过DMA传输回外部存储

## 指令执行

VCore采用VLIW (Very Long Instruction Word)架构，支持并行指令执行：

1. 指令从指令缓存加载
2. 解码为多个并行操作
3. 分发到不同功能单元(VPU、SPU、PEA、DMA)
4. 各单元并行执行各自的操作
5. 同步点确保数据依赖关系得到满足

## 技术实现细节

1. **流水线设计**:
   - 多级指令流水线，包括取指、解码、执行、访存、写回
   - 数据流水线优化，减少计算和数据传输的等待时间
   - 支持指令级并行(ILP)和数据级并行(DLP)

2. **存储层次**:
   - 采用分层存储架构：寄存器 → SM → AM → GSM → DDR
   - 每层存储具有不同的容量、延迟和带宽特性
   - 数据预取机制减少访存延迟

3. **同步机制**:
   - 基于事件(sc_event)的模块间同步
   - 屏障同步确保并行计算的正确性
   - 中断机制处理异常情况

4. **TLM接口**:
   - 所有子模块通过TLM 2.0接口连接
   - 支持阻塞和非阻塞传输模式
   - DMI接口用于高频内存访问优化

5. **时钟域**:
   - 支持多时钟域设计
   - 异步FIFO用于跨时钟域通信
   - 可配置的时钟频率，支持动态频率调整

## 性能特性

- **计算密度**: 每个时钟周期可执行的操作数
- **内存带宽**: AM和SM的峰值访问带宽
- **延迟**: 指令执行和数据访问的平均延迟
- **能效**: 每操作的能耗估计
- **可扩展性**: 支持配置不同规模的计算资源

## 编程模型

VCore支持多种编程接口：

1. **直接指令编程**: 通过汇编级指令直接控制硬件
2. **库函数调用**: 预定义的常用计算函数库
3. **自动编译**: 从高级语言自动生成优化的VCore指令
4. **任务调度**: 支持任务级并行和流水线执行

## 应用优化

VCore架构针对以下计算模式进行了优化：

- 密集矩阵运算(GEMM)
- 卷积神经网络(CNN)
- 傅里叶变换(FFT/IFFT)
- 向量点积和外积
- 数据重排和格式转换
